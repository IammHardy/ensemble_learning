{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daf729c9-15d6-4a2c-9b95-bf6146640ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(r\"C:\\Users\\DoBUY\\Downloads\\train.csv\")\n",
    "\n",
    "# Select features and target\n",
    "X = data[['GrLivArea', 'YearBuilt']].values\n",
    "y = data['SalePrice'].values\n",
    "\n",
    "# Split the data into train and validation sets (80% train, 20% validation)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "411cdf76-903a-452d-8768-16ed476e55af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blending MSE: 2696836742.6874914\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define models\n",
    "models = [\n",
    "    LinearRegression(),\n",
    "    DecisionTreeRegressor(),\n",
    "    SVR()\n",
    "]\n",
    "\n",
    "# Train models\n",
    "for model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "# Generate predictions\n",
    "preds = []\n",
    "for model in models:\n",
    "    preds.append(model.predict(X_val))\n",
    "\n",
    "# Blend predictions (simple averaging)\n",
    "blend_pred = sum(preds) / len(preds)\n",
    "\n",
    "# Evaluate performance\n",
    "mse_blend = mean_squared_error(y_val, blend_pred)\n",
    "print(\"Blending MSE:\", mse_blend)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "729a212b-4278-435a-a6f2-abce92e8ba2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging MSE: 1935217631.3602672\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Number of models (bags)\n",
    "n_models = 5\n",
    "\n",
    "# List to store models\n",
    "models = []\n",
    "\n",
    "# Train n_models on different bootstrap samples\n",
    "for _ in range(n_models):\n",
    "    # Create bootstrap sample\n",
    "    indices = np.random.choice(len(X_train), size=len(X_train), replace=True)\n",
    "    X_bag = X_train[indices]\n",
    "    y_bag = y_train[indices]\n",
    "    \n",
    "    # Train decision tree model\n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_bag, y_bag)\n",
    "    \n",
    "    # Add trained model to list\n",
    "    models.append(model)\n",
    "\n",
    "# Generate predictions\n",
    "bagging_preds = np.zeros_like(y_val, dtype=float)\n",
    "for model in models:\n",
    "    bagging_preds += model.predict(X_val)\n",
    "\n",
    "# Average predictions\n",
    "bagging_preds /= n_models\n",
    "\n",
    "# Calculate MSE\n",
    "mse_bagging = mean_squared_error(y_val, bagging_preds)\n",
    "print(\"Bagging MSE:\", mse_bagging)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "bb497bd5-f596-4bf4-8cea-5b56e8306b21",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (80,) (16,) (80,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 73\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m     71\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m---> 73\u001b[0m final_pred \u001b[38;5;241m=\u001b[39m stacking_model\u001b[38;5;241m.\u001b[39mfit_predict(X_train, y_train, X_test)\n",
      "Cell \u001b[1;32mIn[36], line 20\u001b[0m, in \u001b[0;36mStacking.fit_predict\u001b[1;34m(self, X_train, y_train, X_test, K0, M0)\u001b[0m\n\u001b[0;32m     18\u001b[0m     X_tr, X_val, y_tr, y_val \u001b[38;5;241m=\u001b[39m train_test_split(X_train, y_train, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39mk)\n\u001b[0;32m     19\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_tr, y_tr)\n\u001b[1;32m---> 20\u001b[0m     blend_data \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m     21\u001b[0m     blend_train_stage0[:, \u001b[38;5;28mlen\u001b[39m(models_stage0)] \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_val)\n\u001b[0;32m     22\u001b[0m blend_data \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m K0\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (80,) (16,) (80,) "
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "class Stacking:\n",
    "    def __init__(self, base_models, meta_model):\n",
    "        self.base_models = base_models\n",
    "        self.meta_model = meta_model\n",
    "\n",
    "    def fit_predict(self, X_train, y_train, X_test, K0=3, M0=2):\n",
    "        # Stage 0\n",
    "        models_stage0 = []\n",
    "        blend_train_stage0 = np.zeros((len(X_train), len(self.base_models)))\n",
    "\n",
    "        for model in self.base_models:\n",
    "            blend_data = np.zeros(len(X_train))\n",
    "            for k in range(K0):\n",
    "                X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=k)\n",
    "                model.fit(X_tr, y_tr)\n",
    "                blend_data += model.predict(X_val)\n",
    "                blend_train_stage0[:, len(models_stage0)] = model.predict(X_val)\n",
    "            blend_data /= K0\n",
    "            models_stage0.append(blend_data)\n",
    "\n",
    "        # Stage n\n",
    "        for i in range(1, len(self.base_models)):\n",
    "            blend_data = np.zeros((len(X_train), M0 * i))\n",
    "            for j in range(M0 * i):\n",
    "                base_model_index = j % i\n",
    "                base_model = self.base_models[base_model_index]\n",
    "                X_blend_train = np.hstack([blend_train_stage0[:, k] for k in range(base_model_index, len(self.base_models), i)])\n",
    "                for k in range(K0):\n",
    "                    X_tr, X_val, y_tr, y_val = train_test_split(X_blend_train, y_train, test_size=0.2, random_state=k)\n",
    "                    base_model.fit(X_tr, y_tr)\n",
    "                    blend_data[:, j] = base_model.predict(X_val)\n",
    "            blend_train_stage0 = blend_data\n",
    "\n",
    "        # Final Stage\n",
    "        self.meta_model.fit(blend_train_stage0, y_train)\n",
    "        blend_test = np.zeros((len(X_test), len(self.base_models)))\n",
    "        for i, model in enumerate(self.base_models):\n",
    "            blend_test[:, i] = model.predict(X_test)\n",
    "        final_pred = self.meta_model.predict(blend_test)\n",
    "        return final_pred\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# Instantiate base models\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "base_model1 = DecisionTreeRegressor()\n",
    "base_model2 = LinearRegression()\n",
    "\n",
    "# Instantiate meta model\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Instantiate stacking model\n",
    "stacking_model = Stacking(base_models=[base_model1, base_model2], meta_model=meta_model)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Generate sample dataset\n",
    "np.random.seed(0)\n",
    "X = np.random.rand(100, 2)  # 100 samples, 2 features\n",
    "y = 2 * X[:, 0] - 3 * X[:, 1] + np.random.randn(100)  # Target variable\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "final_pred = stacking_model.fit_predict(X_train, y_train, X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ab5c314-1142-4e23-bf9f-f8bd2c0f6287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(292,)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape\n",
    "\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488b00b2-27ab-415e-8566-38cd2f7db597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
